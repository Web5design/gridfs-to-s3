package Storage::Handler::GridFS;

# class for storing / loading downloads in GridFS (MongoDB)

use strict;
use warnings;

use Moose;
with 'Storage::Handler';

use MongoDB 0.700.0;
use MongoDB::GridFS;

use Log::Log4perl qw(:easy);
Log::Log4perl->easy_init({level => $DEBUG, utf8=>1, layout => "%d{ISO8601} [%P]: %m%n"});

use Storage::Iterator::GridFS;

# MongoDB's query timeout, in ms
# (default timeout is 30 s, but MongoDB sometimes creates a new 2 GB data file for ~38 seconds,
#  so we set it to 60 s)
use constant MONGODB_QUERY_TIMEOUT => 60 * 1000;

# MongoDB's number of read / write retries
# (in case waiting 60 seconds for the read / write to happen doesn't help, the instance should
#  retry writing a couple of times)
use constant MONGODB_READ_RETRIES  => 3;
use constant MONGODB_WRITE_RETRIES => 3;


# Configuration
has '_config_host' => ( is => 'rw' );
has '_config_port' => ( is => 'rw' );
has '_config_database' => ( is => 'rw' );

# MongoDB client, GridFS instance (lazy-initialized to prevent multiple forks using the same object)
has '_mongodb_client' => ( is => 'rw' );
has '_mongodb_database' => ( is => 'rw' );
has '_mongodb_gridfs' => ( is => 'rw' );
has '_mongodb_fs_files_collection' => ( is => 'rw' );

# Process PID (to prevent forks attempting to clone the MongoDB accessor objects)
has '_pid' => ( is => 'rw' );


# Constructor
sub BUILD {
    my $self = shift;
    my $args = shift;

    $self->_config_host($args->{host} || 'localhost');
    $self->_config_port($args->{port} || 27017);
    $self->_config_database($args->{database}) or LOGDIE("Database is not defined.");
    $self->_pid($$);
}

# Validate ObjectId
# (only ObjectIds generated by MongoDB are supported as they contain an insertion timestamp)
sub valid_objectid($)
{
    my $objectid = shift;

    if (length($objectid) == 24 and $objectid =~ /^[0-9a-f]+$/i) {
        return 1;
    } else {
        return 0;
    }
}

sub _connect_to_mongodb_or_die($)
{
    my ( $self ) = @_;

    if ( $self->_pid == $$ and ( $self->_mongodb_client and $self->_mongodb_database and $self->_mongodb_gridfs and $self->_mongodb_fs_files_collection ) )
    {

        # Already connected on the very same process
        return;
    }

    # Connect
    $self->_mongodb_client(MongoDB::MongoClient->new( host => $self->_config_host, port => $self->_config_port, query_timeout => MONGODB_QUERY_TIMEOUT ));
    unless ( $self->_mongodb_client )
    {
        LOGDIE("Unable to connect to MongoDB (" . $self->_config_host . ":" . $self->_config_port . ").");
    }

    $self->_mongodb_database($self->_mongodb_client->get_database( $self->_config_database ));
    unless ( $self->_mongodb_database )
    {
        LOGDIE("Unable to choose a MongoDB database '" . $self->_config_database . "'.");
    }

    $self->_mongodb_fs_files_collection($self->_mongodb_database->get_collection('fs.files'));
    unless ($self->_mongodb_fs_files_collection) {
        LOGDIE("Unable to use MongoDB database's '" . $self->_config_database . "' collection 'fs.files'.");
    }

    $self->_mongodb_gridfs($self->_mongodb_database->get_gridfs);
    unless ( $self->_mongodb_gridfs )
    {
        LOGDIE("Unable to use MongoDB database '" . $self->_config_database . "' as GridFS database.");
    }

    # Save PID
    $self->_pid($$);

    INFO("Connected to GridFS download storage (" . $self->_config_host . ":" . $self->_config_port . "/" . $self->_config_database . ").");
}

sub head($$)
{
    my ( $self, $filename ) = @_;

    $self->_connect_to_mongodb_or_die();

    my $file = $self->_mongodb_gridfs->find_one( { 'filename' => $filename } );

    if ( defined $file )
    {
        return 1;
    } else {
        return 0;
    }
}

sub delete($$)
{
    my ( $self, $filename ) = @_;

    $self->_connect_to_mongodb_or_die();

    # Remove file(s) if already exist(s) -- MongoDB might store several versions of the same file
    while ( my $file = $self->_mongodb_gridfs->find_one( { 'filename' => $filename } ) )
    {
        # "safe -- If true, each remove will be checked for success and die on failure."
        $self->_mongodb_gridfs->remove( { 'filename' => $filename }, { safe => 1 } );
    }

    return 1;
}

sub put($$$)
{
    my ( $self, $filename, $contents ) = @_;

    $self->_connect_to_mongodb_or_die();

    my $gridfs_id;

    # MongoDB sometimes times out when writing because it's busy creating a new data file,
    # so we'll try to write several times
    for ( my $retry = 0 ; $retry < MONGODB_WRITE_RETRIES ; ++$retry )
    {
        if ( $retry > 0 )
        {
            WARN("Retrying...");
        }

        eval {

            # Remove file(s) if already exist(s) -- MongoDB might store several versions of the same file
            while ( my $file = $self->_mongodb_gridfs->find_one( { 'filename' => $filename } ) )
            {
                INFO("Removing existing file '$filename'....");
                $self->delete( $filename );
            }

            # Write
            my $basic_fh;
            open( $basic_fh, '<', \$contents );
            $gridfs_id = $self->_mongodb_gridfs->put( $basic_fh, { 'filename' => $filename } );
            unless ( $gridfs_id )
            {
                LOGDIE("MongoDB's ObjectId is empty.");
            }
        };

        if ( $@ )
        {
            WARN("Attempt to write to '$filename' didn't succeed because: $@");
        }
        else
        {
            last;
        }
    }

    unless ( $gridfs_id )
    {
        LOGDIE("Unable to store download '$filename' to GridFS after " . MONGODB_WRITE_RETRIES . " retries.");
    }

    return 1;
}

sub get($$)
{
    my ( $self, $filename ) = @_;

    $self->_connect_to_mongodb_or_die();

    my $id = MongoDB::OID->new( filename => $filename );

    # MongoDB sometimes times out when reading because it's busy creating a new data file,
    # so we'll try to read several times
    my $attempt_to_read_succeeded = 0;
    my $file                      = undef;
    for ( my $retry = 0 ; $retry < MONGODB_READ_RETRIES ; ++$retry )
    {
        if ( $retry > 0 )
        {
            WARN("Retrying...");
        }

        eval {

            # Read
            $file = $self->_mongodb_gridfs->find_one( { 'filename' => $filename } );
            $attempt_to_read_succeeded = 1;
        };

        if ( $@ )
        {
            WARN("Attempt to read from '$filename' didn't succeed because: $@");
        }
        else
        {
            last;
        }
    }

    unless ( $attempt_to_read_succeeded )
    {
        LOGDIE("Unable to read download '$filename' from GridFS after " . MONGODB_READ_RETRIES . " retries.");
    }

    unless ( defined( $file ) )
    {
        LOGDIE("Could not get file from GridFS for filename '$filename'");
    }

    my $content = $file->slurp;

    return $content;
}

sub list_iterator($;$)
{
    my ( $self, $filename_offset ) = @_;

    $self->_connect_to_mongodb_or_die();

    my $filenames = [];

    my $offset_objectid;
    if ($filename_offset) {
        # Find the ObjectId of the offset filename
        $offset_objectid       = $self->_mongodb_fs_files_collection->find_one({ filename => $filename_offset }, {_id => 1});
        unless ($offset_objectid) {
            LOGDIE("Offset file '$filename_offset' was not found.");
        }
        $offset_objectid = $offset_objectid->{_id}->{value};
        unless (valid_objectid($offset_objectid)) {
            LOGDIE("Offset file's '$filename_offset' ObjectId '$offset_objectid' is not valid.");
        }
    }

    my $find_query = { };
    if ($offset_objectid) {
        $find_query = { _id => { '$gt' => MongoDB::OID->new(value => $offset_objectid) } };
    }

    # Sort by ObjectId because it is indexed and contains an insertion timestamp
    my $cursor = $self->_mongodb_fs_files_collection->query($find_query)->sort({_id => 1})->fields({_id=>1, filename=>1});
    my $iterator = Storage::Iterator::GridFS->new(cursor => $cursor);
    return $iterator;
}

no Moose;    # gets rid of scaffolding

1;
